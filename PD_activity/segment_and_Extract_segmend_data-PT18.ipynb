{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import scipy.signal as signal \n",
    "import scipy\n",
    "import datetime\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from dsmuc.custom import detect_peaks\n",
    "sns.set(style=\"darkgrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../data/data_PD/PT18/\"\n",
    "\n",
    "interested_cols = [ 'AccX', 'AccY', 'AccZ', 'GyroX','GyroY', 'GyroZ']\n",
    "window_size = datetime.timedelta(seconds=2)\n",
    "window_slide = datetime.timedelta(seconds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [ \n",
    "                        'mean',\n",
    "                        'min',\n",
    "                        'max',\n",
    "                        'range',\n",
    "                        'entropy_',\n",
    "                        'var',\n",
    "                        'kurtosis',\n",
    "                        'skew',\n",
    "                        'quantile25',\n",
    "                        'quantile50',\n",
    "                        'quantile75',\n",
    "                        'energy', \n",
    "                        'label',\n",
    "                        'frequency_features',\n",
    "                        'subject_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.mean(a)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_mean'\n",
    "    return var\n",
    "def min_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.min(a)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_min'\n",
    "    return var\n",
    "def max_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.max(a)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_max'\n",
    "    return var\n",
    "def range_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = (np.max(a)-np.min(a))\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_range'\n",
    "    return var\n",
    "def entropy_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        e =np.histogram(a)[0]\n",
    "        var_temp = scipy.stats.entropy(e/ np.sum(e))\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_entropy'\n",
    "    return var\n",
    "def var_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.var(a)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_var'\n",
    "    return var\n",
    "def kurtosis_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = scipy.stats.kurtosis(a, fisher=True)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_kurtosis'\n",
    "    return var\n",
    "def skewness_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = scipy.stats.skew(a)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_skew'\n",
    "    return var\n",
    "def quantile25_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.percentile(a,25)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_q25'\n",
    "    return var\n",
    "def quantile50_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.percentile(a,50)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_q50'\n",
    "    return var\n",
    "def quantile75_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.percentile(a,75)\n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_q75'\n",
    "    return var\n",
    "def energy_(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        var_temp = np.sum(np.mean(a**2)) \n",
    "        list_.append(var_temp)\n",
    "    var = pd.Series(list_, index=interested_cols)\n",
    "    var.index += '_energy'\n",
    "    return var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return idx\n",
    "def frequency_features(df):\n",
    "    list_= []\n",
    "    index_name = []\n",
    "    frequency_features_list = ['energy_total','energy_interested','max_total', 'max_interested']\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        f, psdX = signal.periodogram(a, fs=50, nfft = 256)\n",
    "        i_low = find_nearest(f,4.0)\n",
    "        i_high = find_nearest(f,7.0)\n",
    "\n",
    "        energy_total = np.sum(psdX) \n",
    "        energy_interested = np.sum(psdX[i_low : i_high + 1]) \n",
    "        max_total = np.max(psdX)\n",
    "        max_interested = np.max(psdX[i_low : i_high + 1])\n",
    "        var_temp = [energy_total, energy_interested, max_total, max_interested]\n",
    "        list_.extend(var_temp)\n",
    "        index_name.extend([col+'_'+x for x in frequency_features_list])\n",
    "    var = pd.Series(list_, index=index_name)\n",
    "    return var\n",
    "def average_over_axis(df):\n",
    "    aoa = df[interested_cols].mean(axis = 0)\n",
    "    aoa.index += '_aoa'\n",
    "    return aoa\n",
    "def average_time_elapse(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        mph = a.mean()\n",
    "        ind = detect_peaks(a, mph = mph, mpd=20, show=False)\n",
    "        list_.append(np.diff(ind).mean())\n",
    "    ate = pd.Series(list_, index=interested_cols)\n",
    "    ate.index += '_ate'\n",
    "    return ate\n",
    "def average_peak_freq(df):\n",
    "    list_f= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        mph = a.mean()\n",
    "        ind = detect_peaks(a, mph = mph, mpd=20, show=False)\n",
    "        list_f.append(len(ind)/a.shape[0])\n",
    "    apf = pd.Series(list_f, index=interested_cols)\n",
    "    apf.index += '_apf'\n",
    "    return apf\n",
    "def rms_func(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        rms_temp = np.sqrt(np.mean(a**2))\n",
    "        list_.append(rms_temp)\n",
    "    rms = pd.Series(list_, index=interested_cols)\n",
    "    rms.index += '_rms'\n",
    "    return rms\n",
    "def std_func(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        std_temp = np.std(a)\n",
    "        list_.append(std_temp)\n",
    "    std = pd.Series(list_, index=interested_cols)\n",
    "    std.index += '_std'\n",
    "    return std\n",
    "def minmax_func(df):\n",
    "    list_= []\n",
    "    for col in interested_cols:\n",
    "        a = df[col].values\n",
    "        minmax_temp = np.max(a)-np.min(a)\n",
    "        list_.append(minmax_temp)\n",
    "    minmax = pd.Series(list_, index=interested_cols)\n",
    "    minmax.index += '_minmax'\n",
    "    return minmax\n",
    "def cor_func(df):\n",
    "    a = df[interested_cols[:3]].corr()\n",
    "    b= df[interested_cols[3:]].corr()\n",
    "    indexes = ['CorAccXAccY','CorAccXAccZ','CorAccYAccZ', 'CorGyroXGyroY','CorGyroXGyroZ','CorGyroYGyroZ']\n",
    "    Cor = (a['AccX'][1:]).append(a['AccY'][2:]).append((b['GyroX'][1:]).append(b['GyroY'][2:]))\n",
    "    corr = pd.Series(Cor.values, indexes)\n",
    "    corr.index += '_corr'\n",
    "    return corr\n",
    "def label_(df):\n",
    "    return pd.Series(df['label'][0], index=['label'])\n",
    "def subject_id_(df):\n",
    "    return pd.Series(df['subject_id'][0], index=['subject_id'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_features(df, index, feature_list ):\n",
    "    \n",
    "    feature_func_dict = {\n",
    "                        'aoa':average_over_axis,\n",
    "                        'ate': average_time_elapse,\n",
    "                        'apf':average_peak_freq,\n",
    "                        'rms':rms_func,\n",
    "                        'std':std_func,\n",
    "                        'minimax':minmax_func,\n",
    "                        'cor':cor_func,\n",
    "                        'mean':mean_,\n",
    "                        'min':min_,\n",
    "                        'max':max_,\n",
    "                        'range':range_,\n",
    "                        'entropy_':entropy_,\n",
    "                        'var':var_,\n",
    "                        'kurtosis' : kurtosis_,\n",
    "                        'skew':skewness_,\n",
    "                        'quantile25':quantile25_,\n",
    "                        'quantile50':quantile50_,\n",
    "                        'quantile75':quantile75_,\n",
    "                        'energy':energy_,\n",
    "                        'frequency_features':frequency_features,\n",
    "                        'label':label_,\n",
    "                        'subject_id':subject_id_\n",
    "        }\n",
    "\n",
    "\n",
    "    ser_list = []\n",
    "    ser_list.append(pd.Series(str(index[0]),index=['start']))\n",
    "    ser_list.append(pd.Series(str(index[1]),index=['end']))\n",
    "    for x in feature_list:\n",
    "        ser_list.append(feature_func_dict[x](df))\n",
    "    ser = pd.concat(ser_list)\n",
    "    if type(index)!=str:\n",
    "        index = str(index)\n",
    "    ser.name = index\n",
    "    return ser\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def get_all_features(df, index):\\n    feature_list = ['subject_id', 'aoa', 'ate', 'apf', 'rms', 'std', 'minmax', 'cor', 'label']\\n#     feature_func_dict = {'aoa':average_over_axis,\\n#                         'ate': average_time_elapse,\\n#                         'apf':average_peak_freq,\\n#                         'rms':rms_func,\\n#                         'std':std_func,\\n#                         'minimax':minmax_func,\\n#                         'cor':cor_func}\\n    \\n    aoa = average_over_axis(df)\\n    ate = average_time_elapse(df)\\n    apf = average_peak_freq(df)\\n    rms = rms_func(df)\\n    std = std_func(df)\\n    minmax = minmax_func(df)\\n    cor = cor_func(df)\\n    subject_id = pd.Series(df['subject_id'][0], index=['subject_id'])\\n    label = pd.Series(df['label'][0], index=['label'])\\n    \\n    ser_list = [pd.Series(str(index[0]),index=['start']),pd.Series(str(index[1]),index=['end']), subject_id, aoa, ate,apf, rms,std, minmax, cor, label]\\n    ser = pd.concat(ser_list)\\n    if type(index)!=str:\\n        index = str(index)\\n    ser.name = index\\n    \\n    return ser\\n    \""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def get_all_features(df, index):\n",
    "    feature_list = ['subject_id', 'aoa', 'ate', 'apf', 'rms', 'std', 'minmax', 'cor', 'label']\n",
    "#     feature_func_dict = {'aoa':average_over_axis,\n",
    "#                         'ate': average_time_elapse,\n",
    "#                         'apf':average_peak_freq,\n",
    "#                         'rms':rms_func,\n",
    "#                         'std':std_func,\n",
    "#                         'minimax':minmax_func,\n",
    "#                         'cor':cor_func}\n",
    "    \n",
    "    aoa = average_over_axis(df)\n",
    "    ate = average_time_elapse(df)\n",
    "    apf = average_peak_freq(df)\n",
    "    rms = rms_func(df)\n",
    "    std = std_func(df)\n",
    "    minmax = minmax_func(df)\n",
    "    cor = cor_func(df)\n",
    "    subject_id = pd.Series(df['subject_id'][0], index=['subject_id'])\n",
    "    label = pd.Series(df['label'][0], index=['label'])\n",
    "    \n",
    "    ser_list = [pd.Series(str(index[0]),index=['start']),pd.Series(str(index[1]),index=['end']), subject_id, aoa, ate,apf, rms,std, minmax, cor, label]\n",
    "    ser = pd.concat(ser_list)\n",
    "    if type(index)!=str:\n",
    "        index = str(index)\n",
    "    ser.name = index\n",
    "    \n",
    "    return ser\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "def find_csv_filenames( path_to_dir, suffix=\".csv\" ):\n",
    "    filenames = listdir(path_to_dir)\n",
    "    return [ filename for filename in filenames if filename.endswith( suffix ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting segments and saving file : pt18usv.00024.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting segments and saving file : pt18usv.00013.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-2f73b2a787ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mincrement\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensor_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mwindow_slide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity)\u001b[0m\n\u001b[1;32m   5178\u001b[0m                               \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5179\u001b[0m                               columns=combined_columns)\n\u001b[0;32m-> 5180\u001b[0;31m             \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5182\u001b[0m                 \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcombined_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(self, datetime, numeric, timedelta, coerce, copy)\u001b[0m\n\u001b[1;32m   4064\u001b[0m             self._data.convert(datetime=datetime, numeric=numeric,\n\u001b[1;32m   4065\u001b[0m                                \u001b[0mtimedelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4066\u001b[0;31m                                copy=copy)).__finalize__(self)\n\u001b[0m\u001b[1;32m   4067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4068\u001b[0m     \u001b[0;31m# TODO: Remove in 0.18 or 2017, which ever is sooner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   3463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3465\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'convert'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3328\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mgr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3329\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3330\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mby_item\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_single_block\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2135\u001b[0;31m             \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_and_operate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36msplit_and_operate\u001b[0;34m(self, mask, f, inplace)\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;31m# need a new block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                 \u001b[0mnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                 \u001b[0mnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(m, v, i)\u001b[0m\n\u001b[1;32m   2123\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m             \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2125\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2126\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2127\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "window_size_seconds = 2\n",
    "window_slide_seconds = 1\n",
    "min_samples = 20\n",
    "save_to = '../../data/PT18_preprocessed_extra/'\n",
    "\n",
    "for file_name in find_csv_filenames(data_path):\n",
    "\n",
    "    window_size = datetime.timedelta(seconds=window_size_seconds)\n",
    "    window_slide = datetime.timedelta(seconds=window_slide_seconds)\n",
    "    try:\n",
    "    \n",
    "        df = pd.read_csv(data_path+file_name, index_col=0)\n",
    "\n",
    "        df['date_time'] = pd.to_datetime(df['time'],unit='ms')\n",
    "        df = df.set_index(pd.DatetimeIndex(df['date_time']))\n",
    "\n",
    "        df = df[['accelerometerX', 'accelerometerY', 'accelerometerZ', 'gyroscopeX',\n",
    "               'gyroscopeY', 'gyroscopeZ','label']]\n",
    "\n",
    "        df.columns = interested_cols + ['label']\n",
    "\n",
    "        df['subject_id'] = (file_name.split('.000')[1].split('.')[0])\n",
    "\n",
    "        df = df.sort_index(ascending = True)\n",
    "\n",
    "\n",
    "        df = df.sort_index(ascending = True)\n",
    "        ## Extract Segments\n",
    "\n",
    "\n",
    "        print('Extracting segments and saving file :', file_name)\n",
    "        samples_count = []\n",
    "        DF = pd.DataFrame()\n",
    "\n",
    "        t = df.index[0]\n",
    "        end_time = df.index[-1]\n",
    "        increment = 0\n",
    "        while(t + datetime.timedelta(seconds=1) < end_time):\n",
    "\n",
    "            t_end = t + window_size\n",
    "            sensor_data = df.between_time(t.to_pydatetime().time(), t_end.to_pydatetime().time()\n",
    "                                               ,include_start=True, include_end=False)\n",
    "            if sensor_data.shape[0]>= min_samples:\n",
    "                increment +=1\n",
    "                ser = get_all_features(sensor_data, index=(t, t_end), feature_list=feature_list)\n",
    "                DF = DF.append(ser, verify_integrity=True)\n",
    "\n",
    "            t = t+window_slide\n",
    "\n",
    "        DF.to_csv(save_to+file_name+'_preprocessed.csv', index=True)\n",
    "    except Exception:\n",
    "        print('file: '+file_name+' not readable')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_cs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
