{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "import sys\n",
    "# sys.path.append(\"../dsmuc/\")\n",
    "import dsmuc.io as io\n",
    "import dsmuc.preprocessing as pp\n",
    "import dsmuc.features as ff\n",
    "import dsmuc.custom as cs\n",
    "import pywt\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def dwtdwt(vector):\n",
    "    return pywt.wavedec(vector, 'haar', level=1)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Combine all Datasets collected using G9 and extract necessary Sensor data for \n",
    "processing later on it \n",
    "\n",
    "method to read output file: pd.read_csv(OUT_FOLDER + 'data.csv',index_col='date', parse_dates=True)\n",
    "'''\n",
    "DATA_SET_FOLDER = '/home/ahmet/notebooks/data/G9_data/new_Dataset/'\n",
    "OUT_FOLDER = '/home/ahmet/notebooks/data/G9_data/Raw/'\n",
    "output_file_name = 'combined_raw_stairs.csv' # for stairs dataset change it to 'combined_raw_stairs.csv'\n",
    "    \n",
    "\n",
    "print('Reading each datasets...')\n",
    "big_list = []\n",
    "for file_path in glob.glob(DATA_SET_FOLDER + '/*/*/*'+'.csv'): # for stairs add one more *\n",
    "    basename = os.path.basename(file_path)\n",
    "    if True:\n",
    "        print(\"Reading the file :\", basename)\n",
    "        subject_id = basename.split(\"_\")[0]\n",
    "        df_data = io.read_g9(file=file_path,subject_id=subject_id)\n",
    "        big_list.append(df_data)\n",
    "df_raw = pd.concat(big_list)\n",
    "df_raw.sort_index(ascending=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"file saved as :\",OUT_FOLDER +output_file_name)\n",
    "df_raw.to_csv(OUT_FOLDER +output_file_name, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_label_file(file_path = None):\n",
    "    xl = pd.ExcelFile(label_file_path)\n",
    "    df_label = xl.parse(\"Sheet1\")\n",
    "    df_label = df_label[['start_time', 'end_time','subject', 'label']]\n",
    "    df_label.columns = ['start_time', 'end_time','subject_id', 'label']\n",
    "    return df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data_path = '/home/ahmet/notebooks/data/G9_data/Raw/combined_raw_stairs.csv'\n",
    "label_file_path = '/home/ahmet/notebooks/data/G9_data/new_Dataset/Additional Stairs Dataset/additional_stairs_detail_timestamp.xlsx'\n",
    "out_file_path = '/home/ahmet/notebooks/data/G9_data/Raw/labeled_stairs.csv'\n",
    "print('reading raw data ...')\n",
    "df_raw = pd.read_csv(raw_data_path,index_col=0, parse_dates=True)\n",
    "print('reading label file in excel ...')\n",
    "df_label = read_label_file(label_file_path)\n",
    "\n",
    "df_label['start'] = pd.to_datetime(df_label['start_time'])  \n",
    "df_label['end'] = pd.to_datetime(df_label['end_time']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('labeling data...')\n",
    "df_labeled = pp.label_data(df_data=df_raw, df_label=df_label)\n",
    "print('saving labeled file to the path:'+out_file_path +'...')\n",
    "df_labeled.to_csv(out_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df_labeled['subject_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/ahmet/notebooks/data/G9_data/Raw/labeled.csv\"\n",
    "file_path_stairs = \"/home/ahmet/notebooks/data/G9_data/Raw/labeled_stairs.csv\"\n",
    "saveto = \"/home/ahmet/notebooks/data/G9_data/Raw/snippets3sec/\"\n",
    "label_dict = {1:'walking',\n",
    "             2:'walking upstairs',\n",
    "             3:'walking downstairs',\n",
    "             4:'sitting',\n",
    "             5:'standing',\n",
    "             6:'lying'}\n",
    "interested_cols = [ 'accX', 'accY', 'accZ', 'gyroX','gyroY', 'gyroZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_samples = 20\n",
    "window_size_seconds = 3\n",
    "window_slide_seconds = 1\n",
    "print('Creating output folders for each label')\n",
    "isSure = cs.create_label_folders(label_dict= label_dict, saveto = saveto)\n",
    "if not isSure:\n",
    "    if not cs.query_yes_no('There are already folders specified.Are you sure to continue to extract segment?'):\n",
    "        print('There are already folders specified.Are you sure to continue to extract segment?')\n",
    "    else:\n",
    "        import shutil\n",
    "        print('Clearing the directory: ', saveto)\n",
    "        shutil.rmtree(saveto)\n",
    "        cs.create_label_folders(label_dict= label_dict, saveto = saveto)\n",
    "\n",
    "window_size = datetime.timedelta(seconds=window_size_seconds)\n",
    "window_slide = datetime.timedelta(seconds=window_slide_seconds)\n",
    "\n",
    "\n",
    "df_old = pd.read_csv(file_path, index_col='date', parse_dates=True)\n",
    "df_stairs = pd.read_csv(file_path_stairs, index_col='date', parse_dates=True)\n",
    "df_stairs['subject_id'] = (df_stairs['subject_id']+100)\n",
    "df = pd.concat([df_old, df_stairs])\n",
    "df = df.sort_index(ascending = True)\n",
    "## Extract Segments\n",
    "\n",
    "subject_ids = np.unique(df['subject_id']).tolist()\n",
    "labels = list(label_dict.keys())\n",
    "\n",
    "print('Extracting windows')\n",
    "samples_count = []\n",
    "for s in subject_ids:\n",
    "    print('subject: ',s)\n",
    "    for l in labels:\n",
    "        print('label: ',label_dict[l])\n",
    "        df_temp = df[np.logical_and(df['subject_id']==s, df['label']==l)]\n",
    "        if df_temp.shape[0] !=0:\n",
    "            win_list = pp.ext_windows(df=df_temp,window_size_seconds=window_size_seconds, \\\n",
    "                               window_slide_seconds=window_slide_seconds)\n",
    "            win_list =[win for win in win_list if win.shape[0]>min_samples ]\n",
    "\n",
    "            df_ = pd.DataFrame()\n",
    "            i = 0\n",
    "            index = str(s)+str(l)\n",
    "            for window in win_list:\n",
    "                window.to_csv(saveto+label_dict[l]+'/'+str(s)+\"_\"+str(i)+'.csv')\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.read_csv('/home/ahmet/notebooks/data/G9_data/Raw/snippets3sec/sitting/10_298.csv', index_col='date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_windows_path = \"/home/ahmet/notebooks/data/G9_data/Raw/snippets3sec/\"\n",
    "processed_file_path = \"/home/ahmet/notebooks/data/G9_data/processed_3sec.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34958 windows\n"
     ]
    }
   ],
   "source": [
    "win_paths = glob.glob(raw_windows_path+'*/*.csv')\n",
    "print(\"Found {} windows\".format(len(win_paths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(fp):\n",
    "    win = pd.read_csv(fp, index_col='date', parse_dates=True)\n",
    "    try:\n",
    "        win = pp.resample(win, fs = 128/3)[:128]\n",
    "    except:\n",
    "        return None\n",
    "    if win.shape[0] == 128:\n",
    "        win['accnorm'] = win[[\"accX\", \"accY\", \"accZ\"]].apply(np.linalg.norm, axis = 1)\n",
    "        win['gyronorm'] = win[[\"gyroX\", \"gyroY\", \"gyroZ\"]].apply(np.linalg.norm, axis = 1)\n",
    "        x = win[['accX', 'accY', 'accZ', 'gyroX', 'gyroY', 'gyroZ', 'accnorm', \"gyronorm\"]].values\n",
    "        y = win['label'][0]\n",
    "        z =int(win['subject_id'][0])\n",
    "        return x, y, z\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Parallel(n_jobs=-1)(delayed(process_file)(f) for f in win_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array(a)\n",
    "c = c[c !=None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([x[0] for x in c])\n",
    "y = np.array([x[1] for x in c])\n",
    "z = np.array([x[2] for x in c])\n",
    "X = X.reshape((-1, 8, 128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ahmet/notebooks/data/G9_data/action_data.pkl', 'wb') as f:\n",
    "      cPickle.dump((X,y,z) , f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30489, 8, 128)\n"
     ]
    }
   ],
   "source": [
    "with open('/home/ahmet/notebooks/data/G9_data/action_data.pkl','rb') as f:\n",
    "    X, y, z = cPickle.load(f)\n",
    "    print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "win_list = []\n",
    "i = 0\n",
    "for win in map(lambda w: pd.read_csv(w,index_col='date', parse_dates=True), win_paths):\n",
    "    i += 1 \n",
    "    win['win_index'] = i\n",
    "    win_list.append(win)\n",
    "    if i%200 ==0:\n",
    "        print(i,\"of windows out of \", len(win_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(win_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff.interested_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ff.interested_cols = [ 'accX', 'accY', 'accZ', 'gyroX','gyroY', 'gyroZ', 'win_index']\n",
    "feature_list = ['aoa','ate','apf','rms','std','minimax', 'energy','min','max']\n",
    "preserved_features = ['start','subject_id','label']\n",
    "\n",
    "df_final = ff.extract_features(df, feature_list=feature_list , preserved_features=preserved_features)\n",
    "df_final.dropna()\n",
    "df_final.sort_values('start', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Saving processed file to the path:',processed_file_path)\n",
    "df_final.to_csv(processed_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Feature Calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_windows_path = \"/home/ahmet/notebooks/data/data_PD/snippets/\"\n",
    "processed_file_path = \"/home/ahmet/notebooks/data/data_PD/preprocessed_data_all_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_paths = glob.glob(raw_windows_path+'*/*.csv')\n",
    "print(\"Found {} windows\".format(len(win_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "win_list = []\n",
    "i = 0\n",
    "for win in map(lambda w: pd.read_csv(w,index_col='date', parse_dates=True), win_paths):\n",
    "    i += 1 \n",
    "    win['win_index'] = i\n",
    "    win_list.append(win)\n",
    "    if i%200 ==0:\n",
    "        print(i,\"of windows out of \", len(win_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = ['aoa',\n",
    "'ate',\n",
    "'apf',\n",
    "'rms',\n",
    "'std',\n",
    "'minimax',\n",
    "'cor',\n",
    "'mean',\n",
    "'min',\n",
    "'max',\n",
    "'range',\n",
    "'entropy',\n",
    "'var',\n",
    "'kurtosis',\n",
    "'skew',\n",
    "'quantile25',\n",
    "'quantile50',\n",
    "'quantile75',\n",
    "'energy',\n",
    "'frequency_features',\n",
    "'acc_norm_mean',\n",
    "'acc_norm_std',\n",
    "'gyro_norm_mean',\n",
    "'gyro_norm_std',\n",
    "'mazilu_power',\n",
    "'acc_mean_crossings',\n",
    "'gyro_mean_crossings',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import dsmuc.features as ff\n",
    "feature_list = features_all\n",
    "preserved_features=['start', 'subject_id', 'label']\n",
    "df_final = pd.DataFrame()\n",
    "index = 0\n",
    "for window in win_list:\n",
    "    df_final = df_final.append(ff.extract_features(window, index=index, feature_list=feature_list ,\\\n",
    "    preserved_features=preserved_features))\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.sort_values('start', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Saving processed file to the path:',processed_file_path)\n",
    "df_final.to_csv(processed_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
